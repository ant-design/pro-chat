---
title: Introduction to large model output parameters
group:
  title: Get Started
order: 5
---

# Introduction to large model output parameters

## Overview of Large Models in the Market

In the field of artificial intelligence, LLM (Large Language Models) refers to large-scale machine learning models trained to process, understand, and generate natural language text. Currently, well-known LLMs on the market include:

- **GPT series of OpenAI**: GPT-3 is the most well-known version, known for its powerful natural language processing capabilities.
- **Google's BERT**: BERT focuses on understanding the relationship between words and other words.

These models usually provide services through APIs, allowing developers to send requests to the model and receive response data.

## Return structure of large models and ChatGPT example

### Description of returned parameters

When we send a request to an LLM, we get a JSON-formatted response containing multiple fields. These fields usually contain the following information:

- `id`: Unique identifier used to track a specific request or conversation.
- 'object': usually indicates the response type, such as command output, chat response, etc.
- 'created': The creation timestamp, indicating the response generation time.
- 'model': The name and version of the model used.
- 'choices': contains one or more output objects, each representing a possible answer or result.

### Example returned by ChatGPT

Suppose we use the ChatGPT API provided by OpenAI to send a message and receive the following JSON response as an example:

```json
{
  "id": "cmpl-example",
  "object": "text_completion",
  "created": 1616510934,
  "model": "gpt-3.5-turbo",
  "choices": [
    {
      "text": "\nThis is a response from the model.",
      "index": 0,
      "logprobs": null,
      "finish_reason": "length"
    }
  ]
}
```

### Parameter Analysis

In this example:

- 'id' indicates that this interaction has a specific identifier: 'cmpl-example'.
- 'object' indicates that this is a text completion type: 'text_completion'.
- 'created' describes when the reply was created: '1616510934' (UNIX timestamp format).
- The 'model' tag indicates which AI model is used: 'gpt-3.5-turbo'.
- In the `choices` array: The 'text' field provides the text content generated by the model;
- `index`: Indicates the index position of the current selection in the array;
- If configured, it is used to display information such as the probability of each token; Finally, the output process is ended according to different conditions.

## Streaming vs Non-Streaming API Interfaces

### Streaming interface

The streaming interface can send and receive data continuously. In this case, the return parameters may include some additional information to mark the status of the data stream:

```json
{
  ...
  "finish_reason": null,
"finish_reason": "complete", // complete means the SSE request is complete
}
```

For example, in a continuous conversation scenario, if the 'finish_reason' returns 'null', it means that the conversation has not ended yet, and 'complete' indicates that the 'SSE' request has been completed.

> For more information about the SSE streaming interface, refer to [What is streaming output?](./sse.md)

### Non-streaming interface

A non-streaming interface usually means that a complete response is returned only once per request. Using the example of ChatGPT's response above as a guide, there are no fields such as 'finish_reason' in a non-streaming interface because there is no need for continuous interaction.

> For example, here is a general non-streaming request interface for Qianwen, as follows

```json
{
  "status_code": 200,
  "request_id": "05dc83af-7185-9e14-9b0b-4466de159d6a",
  "code": "",
  "message": "",
  "output": {
    "text": null,
    "finish_reason": null,
    "choices": [
      {
        "finish_reason": "stop",
        "message": {
          "role": "assistant",
          "content": "First, prepare two eggs, a tomato, and appropriate amounts of salt, sugar, cooking wine, and soy sauce. Whisk the eggs in a bowl and mix evenly. Cut the tomato into pieces. Add oil to the pot and heat it. Add the egg mixture and stir-fry until golden brown. Remove and set aside. Add oil to the pot and heat it. Add the tomato pieces and stir-fry evenly. Add appropriate amounts of salt, sugar, cooking wine, and soy sauce. Stir-fry until the tomatoes are soft and mushy. Add the fried eggs and stir-fry evenly."
        }
      }
    ]
  },
  "usage": {
    "input_tokens": 12,
    "output_tokens": 98,
    "total_tokens": 110
  }
}
```
